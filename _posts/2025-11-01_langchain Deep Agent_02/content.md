---
title: å­¦ä¹ è®°å½•â€”â€”LangChain Academy Deep Agents with LangGraph 02
tags: [å­¦ä¹ è®°å½•, LangChain, Reqable]
comments: true
toc: true
---

## è¯¾ç¨‹ä»£ç 

### Agentå®šä¹‰

```python
from IPython.display import Image, display
from langgraph.prebuilt import create_react_agent


from deep_agents_from_scratch.prompts import TODO_USAGE_INSTRUCTIONS
from deep_agents_from_scratch.state import DeepAgentState
from deep_agents_from_scratch.todo_tools import read_todos, write_todos, web_search


from utils import get_model, format_messages

model = get_model()
tools = [write_todos, web_search, read_todos]

# Add mock research instructions
SIMPLE_RESEARCH_INSTRUCTIONS = """IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer the user's question."""

system_p = TODO_USAGE_INSTRUCTIONS  + "\n\n" + "=" * 80 + "\n\n" + SIMPLE_RESEARCH_INSTRUCTIONS
# Create agent
agent = create_react_agent(
    model,
    tools,
    prompt=system_p,
    state_schema=DeepAgentState,
)

# Show the agent
display(Image(agent.get_graph(xray=True).draw_mermaid_png()))

# Example usage
result = agent.invoke(
    {
        "messages": [
            {
                "role": "user",
                "content": "Give me a short summary of the Model Context Protocol (MCP).",
            }
        ],
        "todos": [],
    }
)

format_messages(result["messages"])
```

### çŠ¶æ€å®šä¹‰

```python
"""State management for deep agents with TODO tracking and virtual file systems.

This module defines the extended agent state structure that supports:
- Task planning and progress tracking through TODO lists
- Context offloading through a virtual file system stored in state
- Efficient state merging with reducer functions for files field
"""

from typing import Annotated, Literal, NotRequired
from typing_extensions import TypedDict

from langgraph.prebuilt.chat_agent_executor import AgentState


class Todo(TypedDict):
    """A structured task item for tracking progress through complex workflows

    Attributes:
        content: Short, specific description of the task
        status: Current state - pending, in_progress, or completed
    """

    content: str
    status: Literal["pending", "in_progress", "completed"]

def file_reducer(left, right):
    """Merge two file dictionaries, with right side taking precedence.

    Used as a reducer function for the files field in agent state,
    allowing incremental updates to the virtual file system.

    Args:
        left: Left side dictionary (existing files)
        right: Right side dictionary (new/updated files)

    Returns:
        Merged dictionary with right values overriding left values
    """
    if left is None:
        return right
    elif right is None:
        return left
    else:
        return {**left, **right}

class DeepAgentState(AgentState):
    """Extended agent state that includes task tracking and virtual file system.

    Inherits from LangGraph's AgentState and adds:
    - todos: List of Todo items for task planning and progress tracking
    - files: Virtual file system stored as dict mapping filenames to content
    """

    todos: NotRequired[list[Todo]]
    files: Annotated[NotRequired[dict[str, str]], file_reducer]
```

### å·¥å…·å®šä¹‰

```python
"""TODO management tools for task planning and progress tracking.

This module provides tools for creating and managing structured task lists
that enable agents to plan complex workflows and track progress through
multi-step operations.
"""

from typing import Annotated

from langchain_core.messages import ToolMessage
from langchain_core.tools import InjectedToolCallId, tool
from langgraph.prebuilt import InjectedState
from langgraph.types import Command

from deep_agents_from_scratch.prompts import WRITE_TODOS_DESCRIPTION
from deep_agents_from_scratch.state import DeepAgentState, Todo


@tool(description=WRITE_TODOS_DESCRIPTION,parse_docstring=True)
def write_todos(
    todos: list[Todo], tool_call_id: Annotated[str, InjectedToolCallId]
) -> Command:
    """Create or update the agent's TODO list for task planning and tracking.

    Args:
        todos: List of Todo items with content and status
        tool_call_id: Tool call identifier for message response

    Returns:
        Command to update agent state with new TODO list
    """
    return Command(
        update={
            "todos": todos,
            "messages": [
                ToolMessage(f"Updated todo list to {todos}", tool_call_id=tool_call_id)
            ],
        }
    )


@tool(parse_docstring=True)
def read_todos(
    state: Annotated[DeepAgentState, InjectedState],
    tool_call_id: Annotated[str, InjectedToolCallId],
) -> str:
    """Read the current TODO list from the agent state.

    This tool allows the agent to retrieve and review the current TODO list
    to stay focused on remaining tasks and track progress through complex workflows.

    Args:
        state: Injected agent state containing the current TODO list
        tool_call_id: Injected tool call identifier for message tracking

    Returns:
        Formatted string representation of the current TODO list
    """
    todos = state.get("todos", [])
    if not todos:
        return "No todos currently in the list."

    result = "Current TODO List:\n"
    for i, todo in enumerate(todos, 1):
        status_emoji = {"pending": "â³", "in_progress": "ğŸ”„", "completed": "âœ…"}
        emoji = status_emoji.get(todo["status"], "â“")
        result += f"{i}. {emoji} {todo['content']} ({todo['status']})\n"

    return result.strip()


# Mock search result
search_result = """The Model Context Protocol (MCP) is an open standard protocol developed 
by Anthropic to enable seamless integration between AI models and external systems like 
tools, databases, and other services. It acts as a standardized communication layer, 
allowing AI models to access and utilize data from various sources in a consistent and 
efficient manner. Essentially, MCP simplifies the process of connecting AI assistants 
to external services by providing a unified language for data exchange. """


# Mock search tool
@tool(parse_docstring=True)
def web_search(
    query: str,
):
    """Search the web for information on a specific topic.

    This tool performs web searches and returns relevant results
    for the given query. Use this when you need to gather information from
    the internet about any topic.

    Args:
        query: The search query string. Be specific and clear about what
               information you're looking for.

    Returns:
        Search results from search engine.

    Example:
        web_search("machine learning applications in healthcare")
    """
    return search_result
```

## å®è·µæ€»ç»“

### 1. Jupyter é­”æ³•å‘½ä»¤ï¼š`%%writefile`

- **ç”¨é€”ï¼š** è¿™æ˜¯ä¸€ä¸ª Jupyter Notebook/Google Colab ä¸­çš„â€œé­”æ³•å‘½ä»¤â€ã€‚
- **åŠŸèƒ½ï¼š** å®ƒå°†å…¶æ‰€åœ¨çš„æ•´ä¸ªä»£ç å•å…ƒæ ¼ï¼ˆcellï¼‰çš„å†…å®¹**å†™å…¥åˆ°ä¸€ä¸ªæŒ‡å®šçš„æ–‡ä»¶ä¸­**ã€‚
- **ç¤ºä¾‹ï¼š** `%%writefile ./my_script.py` ä¼šåˆ›å»ºï¼ˆæˆ–è¦†ç›–ï¼‰ä¸€ä¸ªåä¸º `my_script.py` çš„æ–‡ä»¶ï¼Œå¹¶å°†å•å…ƒæ ¼ä¸­çš„æ‰€æœ‰ä»£ç æ”¾å…¥è¯¥æ–‡ä»¶ä¸­ã€‚è¿™æ˜¯åœ¨ Notebook ç¯å¢ƒä¸­ç›´æ¥åˆ›å»º `.py` è„šæœ¬çš„å¿«æ·æ–¹å¼ã€‚

### 2. Python å­—å…¸è§£åŒ…ï¼š`{**left, **right}` 

- **ç”¨é€”ï¼š** è¿™æ˜¯ Python 3.5+ ä¸­ä¸€ç§**åˆå¹¶ä¸¤ä¸ªå­—å…¸**çš„ç®€æ´è¯­æ³•ã€‚
- **åŠŸèƒ½ï¼š** `**` è¿ç®—ç¬¦ä¼šâ€œè§£åŒ…â€å­—å…¸ã€‚è¿™è¡Œä»£ç ä¼šåˆ›å»ºä¸€ä¸ªæ–°å­—å…¸ï¼Œå…ˆå¡«å…¥ `left` çš„æ‰€æœ‰é”®å€¼å¯¹ï¼Œç„¶åå¡«å…¥ `right` çš„æ‰€æœ‰é”®å€¼å¯¹ã€‚
- **å…³é”®è¡Œä¸ºï¼š** å¦‚æœ `left` å’Œ `right` æœ‰ç›¸åŒçš„é”®ï¼ˆkeyï¼‰ï¼Œ**`right` ä¸­çš„å€¼ä¼šè¦†ç›– `left` ä¸­çš„å€¼**ã€‚è¿™åœ¨ä½ ä»£ç ä¸­çš„ `file_reducer` å‡½æ•°ä¸­éå¸¸é‡è¦ï¼Œå®ƒå®ç°äº†â€œå³ä¾§ä¼˜å…ˆâ€çš„æ›´æ–°é€»è¾‘ã€‚

### 3. Python ç±»å‹æç¤º (Type Hinting)

ç±»å‹æç¤ºï¼ˆType Hintingï¼‰ä¸æ”¹å˜ä»£ç çš„è¿è¡Œé€»è¾‘ï¼Œä½†èƒ½æå¤§æé«˜ä»£ç çš„å¯è¯»æ€§ï¼Œå¹¶å¸®åŠ©ä»£ç ç¼–è¾‘å™¨å’Œæ£€æŸ¥å·¥å…·ï¼ˆå¦‚ MyPyï¼‰åœ¨**è¿è¡Œå‰**å°±å‘ç°æ½œåœ¨çš„é”™è¯¯ã€‚

#### `TypedDict` (ç±»å‹åŒ–å­—å…¸)

- **ç”¨é€”ï¼š** æ¥è‡ª `typing` æˆ– `typing_extensions` åº“ï¼Œç”¨äºä¸ºå­—å…¸**å®šä¹‰ä¸€ä¸ªå›ºå®šçš„ç»“æ„**ã€‚
- **åŠŸèƒ½ï¼š** å®ƒå…è®¸ä½ å£°æ˜ä¸€ä¸ªå­—å…¸*å¿…é¡»*åŒ…å«å“ªäº›é”®ï¼Œä»¥åŠæ¯ä¸ªé”®å¯¹åº”çš„*å€¼*åº”è¯¥æ˜¯å“ªç§æ•°æ®ç±»å‹ã€‚
- **ç¤ºä¾‹ï¼š** `class Todo(TypedDict): content: str` å®šä¹‰äº†ä¸€ä¸ªç±»å‹ï¼Œä»»ä½•è¢«æ ‡æ³¨ä¸º `Todo` çš„å˜é‡éƒ½å¿…é¡»æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä¸”å¿…é¡»æœ‰ä¸€ä¸ªé”® `content`ï¼Œå…¶å€¼å¿…é¡»æ˜¯å­—ç¬¦ä¸²ã€‚

#### `NotRequired` (éå¿…éœ€é”®)

- **ç”¨é€”ï¼š** ä¸“ç”¨äº `TypedDict`ï¼ˆæˆ– LangGraph `AgentState` è¿™ç§ç±»å­—å…¸ç»“æ„ï¼‰ã€‚
- **åŠŸèƒ½ï¼š** å®ƒæ ‡è®° `TypedDict` ä¸­çš„æŸä¸ªé”®æ˜¯**å¯é€‰çš„**ï¼Œä¸æ˜¯å¿…é¡»å­˜åœ¨çš„ã€‚
- **ç¤ºä¾‹ï¼š** `class State(TypedDict): todos: NotRequired[list]` æ„å‘³ç€åœ¨ `State` å­—å…¸ä¸­ï¼Œ`todos` è¿™ä¸ªé”®å¯ä»¥å­˜åœ¨ï¼Œä¹Ÿå¯ä»¥ä¸å­˜åœ¨ã€‚è¿™åœ¨ LangGraph çš„ agent çŠ¶æ€ç®¡ç†ä¸­å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºä¸æ˜¯æ¯ä¸€æ­¥éƒ½ä¼šæ›´æ–°æ‰€æœ‰çŠ¶æ€ã€‚

### 4. LangChain å·¥å…·å®šä¹‰ï¼š`@tool` 

`@tool` è£…é¥°å™¨æ˜¯å°†ä¸€ä¸ª Python å‡½æ•°è½¬æ¢ä¸º AI (LLM) å¯ä»¥è°ƒç”¨çš„å·¥å…·çš„æ ¸å¿ƒã€‚

#### `parse_docstring=True`

- **ç”¨é€”ï¼š** è¿™æ˜¯ä¸€ä¸ªä¼ é€’ç»™ `@tool` è£…é¥°å™¨çš„å‚æ•°ã€‚
- **åŠŸèƒ½ï¼š** å®ƒå‘Šè¯‰è£…é¥°å™¨å»**è‡ªåŠ¨è§£æ**è¯¥å‡½æ•°ä¸‹æ–¹çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆdocstringï¼Œå³ `"""..."""` ä¸­çš„å†…å®¹ï¼‰ï¼Œç‰¹åˆ«æ˜¯ `Args:` (æˆ– `Parameters:`) éƒ¨åˆ†ã€‚
- **ç›®çš„ï¼š** å®ƒä¼šæå–å‡ºä½ ä¸ºæ¯ä¸ªå‚æ•°ï¼ˆargumentï¼‰ç¼–å†™çš„æè¿°æ–‡å­—ï¼Œå¹¶å°†è¿™äº›æè¿°ä¿¡æ¯æä¾›ç»™ AIã€‚è¿™èƒ½å¸®åŠ© AI æ›´å‡†ç¡®åœ°ç†è§£**æ¯ä¸ªå‚æ•°çš„å«ä¹‰**ï¼Œä»è€Œæ›´æ™ºèƒ½åœ°è°ƒç”¨è¯¥å·¥å…·ã€‚

#### `parse_docstring` çš„é»˜è®¤å€¼ä¸è®¾è®¡å“²å­¦

- **é»˜è®¤å€¼ï¼š** `parse_docstring` **é»˜è®¤ä¸º `False`**ã€‚
- **ä¸è®¾ç½®ä¼šæ€æ ·ï¼š** å¦‚æœä¸è®¾ç½®ï¼ˆå³ä½¿ç”¨é»˜è®¤çš„ `False`ï¼‰ï¼Œ`@tool` è£…é¥°å™¨**ä¸ä¼š**å»è§£æ `Args:` éƒ¨åˆ†ã€‚AI ä»ç„¶çŸ¥é“å·¥å…·çš„å‚æ•°åç§°ï¼ˆå¦‚ `todos`ï¼‰å’Œç±»å‹ï¼ˆå¦‚ `list[Todo]`ï¼‰ï¼Œä½†**ä¸çŸ¥é“**è¿™äº›å‚æ•°çš„å…·ä½“æè¿°ï¼ˆå³â€œè¿™ä¸ªå‚æ•°æ˜¯ç”¨æ¥å¹²å˜›çš„â€ï¼‰ã€‚
- **ä¸ºä½•ä¸é»˜è®¤å¼€å¯ï¼š**
  1. **å¥å£®æ€§ï¼š** å¼€å¯æ­¤åŠŸèƒ½ä¾èµ–äº**ä¸¥æ ¼çš„ docstring æ ¼å¼**ï¼ˆå¦‚ Google é£æ ¼ï¼‰ã€‚å¦‚æœé»˜è®¤å¼€å¯ï¼Œä»»ä½•å¼€å‘è€…ä¸è§„èŒƒçš„æ³¨é‡Šéƒ½å¯èƒ½å¯¼è‡´ç¨‹åºåœ¨è§£ææ—¶æŠ¥é”™ã€‚é»˜è®¤ `False` ä¿è¯äº†ä»£ç çš„ç¨³å®šè¿è¡Œã€‚
  2. **æ˜ç¡®æ€§ï¼š** éµå¾ª Python çš„â€œæ˜¾å¼ä¼˜äºéšå¼â€å“²å­¦ã€‚å½“ä½ æ‰‹åŠ¨å†™å…¥ `parse_docstring=True` æ—¶ï¼Œä½ æ˜¯åœ¨æ˜ç¡®åœ°å‘Šè¯‰ç³»ç»Ÿï¼šâ€œæˆ‘çŸ¥é“è¿™ä¸ªåŠŸèƒ½ï¼Œå¹¶ä¸”æˆ‘å·²ç¡®ä¿æˆ‘çš„ docstring æ ¼å¼æ­£ç¡®ã€‚â€
  3. **æ›¿ä»£æ–¹æ¡ˆï¼š** åœ¨å¤æ‚çš„å·¥å…·ä¸­ï¼Œæ›´æ¨èä½¿ç”¨ Pydantic æ¨¡å‹ï¼ˆé€šè¿‡ `args_schema` å‚æ•°ï¼‰æ¥å®šä¹‰å‚æ•°ï¼Œå®ƒæä¾›äº†æ›´å¼ºå¤§ã€æ›´æ˜ç¡®çš„éªŒè¯å’Œæè¿°åŠŸèƒ½ã€‚

## LLM APIè¯·æ±‚æ‹¦æˆª

ç¯å¢ƒè¯´æ˜ï¼š`LangChain (Docker Container)` --> `WSL2` --> `Windows 11 Host (Reqable)` --> `Internet (DeepSeek)`

ä½¿ç”¨Reqableä»£ç†ä»£ç†æ‰€æœ‰LLM APIè¯·æ±‚

- å¯åŠ¨Reqableï¼Œé»˜è®¤ä¼šå¼€å¯9000ç«¯å£ä½œä¸ºä»£ç†æœåŠ¡

- åˆ›å»ºè‡ªå®šä¹‰å®¢æˆ·ç«¯å¹¶åœ¨æ¨¡å‹ä¸­ä½¿ç”¨

  - ```python
    from langchain_openai import ChatOpenAI
    import os
    import httpx
    PROXY_URL = "http://host.docker.internal:9000"
    # 1. åˆ›å»º httpx å®¢æˆ·ç«¯
    client = httpx.Client(
        # 2. è®¾ç½®ä»£ç†
        proxy=PROXY_URL,
        # 3. ä¿¡ä»» Reqable çš„è¯ä¹¦ (åœ¨å®¹å™¨å†…è¿›è¡Œè¯ä¹¦éªŒè¯å¾ˆéº»çƒ¦)ï¼Œå¯¹äºæœ¬åœ°è°ƒè¯•ï¼Œç›´æ¥è·³è¿‡éªŒè¯æ˜¯æœ€ç®€å•çš„æ–¹æ³•ã€‚
        verify=False
    )
    model = ChatOpenAI(
        openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
        openai_api_base=os.getenv("DEEPSEEK_API_BASE_URL"),
        model="deepseek-chat",
        http_client=client  # <-- åœ¨è¿™é‡Œä½¿ç”¨é…ç½®å¥½çš„å®¢æˆ·ç«¯
    )
    ```

  - è¯´æ˜ï¼šDocker Desktopï¼ˆåœ¨ WSL2 æ¨¡å¼ä¸‹ï¼‰æä¾›äº†ä¸€ä¸ªç‰¹æ®Šçš„ DNS åç§°æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š`host.docker.internal`ã€‚è¿™ä¸ªåœ°å€**åœ¨å®¹å™¨å†…éƒ¨**ä¼šè¢«è‡ªåŠ¨è§£æä¸º Windows 11 ä¸»æœºçš„ IP åœ°å€ã€‚
  - æ‹¦æˆªç»“æœï¼š
  - ![image-20251102003015386](pic/image-20251102003015386.png)